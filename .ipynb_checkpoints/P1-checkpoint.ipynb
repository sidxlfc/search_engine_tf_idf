{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 4334/5334 Programming Assignment 1 (P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due: 11:59pm Central Time, Tuesday, October 18, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will implement a toy \"search engine\" in Python. You code will read a corpus and produce TF-IDF vectors for documents in the corpus. Then, given a query string, you code will return the query answer--the document with the highest cosine similarity score for the query. Instead of computing cosine similarity score for each and every document, you will implement a smarter threshold-bounding algorithm which shares the same basic principle as real search engines. \n",
    "\n",
    "The instructions on this assignment are written in an .ipynb file. You can use the following commands to install the Jupyter notebook viewer. You can use the following commands to install the Jupyter notebook viewer. \"pip\" is a command for installing Python packages. You are required to use Python 3.5.1 in this project. \n",
    "\n",
    "    pip install jupyter\n",
    "\n",
    "    pip install notebook (You might have to use \"sudo\" if you are installing them at system level)\n",
    "\n",
    "To run the Jupyter notebook viewer, use the following command:\n",
    "\n",
    "    jupyter notebook P1.ipynb\n",
    "\n",
    "The above command will start a webservice at http://localhost:8888/ and display the instructions in the '.ipynb' file.\n",
    "\n",
    "The same instructions are also available at https://nbviewer.jupyter.org/url/crystal.uta.edu/~cli/cse5334/ipythonnotebook/P1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This assignment must be done individually. You must implement the whole assignment by yourself. Academic dishonety will have serious consequences.\n",
    "* You can discuss topics related to the assignment with your fellow students. But you are not allowed to discuss/share your solution and code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a corpus of all the general election presidential debates from 1960 to 2012. We processed the corpus and provided you a .zip file, which includes 30 .txt files. Each of the 30 files contains the transcript of a debate and is named by the date of the debate. The .zip file can be downloaded from Blackboard (\"Course Materials\" > \"Programming Assignment 1\" > \"Attached Files: presidential_debates.zip\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You are required to use Python 3.5.1. You are required to submit a single .py file of your code. We will test your code under the particular version of Python 3.5.1. So make sure you develop your code using the same version. \n",
    "\n",
    "2. You are expected to use several modules in NLTK--a natural language processing toolkit for Python. NLTK doesn't come with Python by default. You need to install it and \"import\" it in your .py file. NLTK's website (http://www.nltk.org/index.html) provides a lot of useful information, including a book http://www.nltk.org/book/, as well as installation instructions (http://www.nltk.org/install.html).\n",
    "\n",
    "3. In programming assignment 1, other than NLTK, you are not allowed to use any other non-standard Python package. However, you are free to use anything from the the Python Standard Library that comes with Python 3.5.1 (https://docs.python.org/3/library/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You code should accomplish the following tasks:\n",
    "\n",
    "(1) <b>Read</b> the 30 .txt files, each of which has the transcript of a presidential debate. The following code does it. Make sure to replace \"corpusroot\" by your directory where the files are stored. In the example below, \"corpusroot\" is a sub-folder named \"presidential_debates\" in the folder containing the python file of the code. \n",
    "\n",
    "In this assignment we ignore the difference between lower and upper cases. So convert the text to lower case before you do anything else with the text. For a query, also convert it to lower case before you answer the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "corpusroot = './presidential_debates'\n",
    "for filename in os.listdir(corpusroot):\n",
    "    file = open(os.path.join(corpusroot, filename), \"r\", encoding='UTF-8')\n",
    "    doc = file.read()\n",
    "    file.close() \n",
    "    doc = doc.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) <b>Tokenize</b> the content of each file. For this, you need a tokenizer. For example, the following piece of code uses a regular expression tokenizer to return all course numbers in a string. Play with it and edit it. You can change the regular expression and the string to observe different output results. \n",
    "\n",
    "For tokenizing the Presidential debate speeches, let's all use RegexpTokenizer(r'[a-zA-Z]+'). What tokens will it produce? What limitations does it have? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSE4334', 'CSE5334', 'IE3013']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'[A-Z]{2,3}[1-9][0-9]{3,3}')\n",
    "tokens = tokenizer.tokenize(\"CSE4334 and CSE5334 are taught together. IE3013 is an undergraduate course.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Perform <b>stopword removal</b> on the obtained tokens. NLTK already comes with a stopword list, as a corpus in the \"NLTK Data\" (http://www.nltk.org/nltk_data/). You need to install this corpus. Follow the instructions at http://www.nltk.org/data.html. You can also find the instruction in this book: http://www.nltk.org/book/ch01.html (Section 1.2 Getting Started with NLTK). Basically, use the following statements in Python interpreter. A pop-up window will appear. Click \"Corpora\" and choose \"stopwords\" from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the stopword list is downloaded, you will find a file \"english\" in folder nltk_data/corpora/stopwords, where folder nltk_data is the download directory in the step above. The file contains 127 stopwords. nltk.corpus.stopwords will give you this list of stopwords. Try the following piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', 'd', 'did', 'didn', 'do', 'does', 'doesn', 'doing', 'don', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', 'has', 'hasn', 'have', 'haven', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', 'more', 'most', 'mustn', 'my', 'myself', 'needn', 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', 'she', 'should', 'shouldn', 'so', 'some', 'such', 't', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', 'we', 'were', 'weren', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', 'wouldn', 'y', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))\n",
    "print(sorted(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Also perform <b>stemming</b> on the obtained tokens. NLTK comes with a Porter stemmer. Try the following code and learn how to use the stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studi\n",
      "vector\n",
      "entropi\n",
      "hispan\n",
      "ambassador\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('studying'))\n",
    "print(stemmer.stem('vector'))\n",
    "print(stemmer.stem('entropy'))\n",
    "print(stemmer.stem('hispanic'))\n",
    "print(stemmer.stem('ambassador'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Using the tokens, compute the <b>TF-IDF vector</b> for each document. Use the following equation that we learned in the lectures to calculate the term weights, in which $t$ is a token and $d$ is a document:  $$w_{t,d} = (1+log_{10}{tf_{t,d}})\\times(log_{10}{\\frac{N}{df_t}}).$$ Note that the TF-IDF vectors should be normalized (i.e., their lengths should be 1). \n",
    "\n",
    "Represent a TF-IDF vector by a dictionary. The following is a sample TF-IDF vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lack': 0.008576372825970286,\n",
       " 'regret': 0.009491784747267843,\n",
       " 'sanction': 0.014972337775895645,\n",
       " 'winter': 0.030424375278541155}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'sanction': 0.014972337775895645, 'lack': 0.008576372825970286, 'regret': 0.009491784747267843, 'winter': 0.030424375278541155}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Given a query string, calculate the query vector. (Remember to convert it to lower case.) In calculating the query vector, don't consider IDF. I.e., use the following equation to calculate the term weights in the query vector, in which $t$ is a token and $q$ is the query: $$w_{t,q} = (1+log_{10}{tf_{t,q}}).$$\n",
    "The vector should also be normalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Find the document that attains the highest <b>cosine similarity</b> score. If we compute the cosine similarity between the query vector and every document vector, it is too inefficient. Instead, implement the following method:\n",
    "\n",
    "(7.1) For each token $t$ that exists in the corpus, construct its <b>postings list</b>---a sorted list in which each element is in the form of (document $d$, TF-IDF weight $w$). Such an element provides $t$'s weight $w$ in document $d$. The elements in the list are sorted by weights in descending order. \n",
    "\n",
    "(7.2) For each token $t$ in the query, return the top-10 elements in its corresponding postings list. If the token $t$ doesn't exist in the corpus, ignore it. \n",
    "\n",
    "(7.3) If a document $d$ appears in the top-10 elements of every query token, calculate $d$'s cosine similarity score. Recall that the score is defined as follows. Since $d$ appears in top-10 of all query tokens, we have all the information to calculate its actual score $sim(q,d)$.\n",
    "\n",
    "$$ sim(q,d) = \\vec{q} \\cdot \\vec{d} = \\sum_{t\\ \\text{in both q and d}} w_{t,q} \\times w_{t,d}.$$\n",
    "\n",
    "(7.4) If a document $d$ doesn't appear in the top-10 elements of some query token $t$, use the weight in the 10th element as the upper-bound on $t$'s weight in $d$'s vector. Hence, we can calculate the upper-bound score for $d$ using the query tokens' actual and upper-bound weights with respect to $d$'s vector, as follows. \n",
    "\n",
    "$$ \\overline{sim(q,d)} = \\sum_{t \\in T_1} w_{t,q} \\times w_{t,d} + \\sum_{t\\in T_2} w_{t,q} \\times \\overline{w_{t,d}}.$$\n",
    "\n",
    "In the above equation, $T_1$ includes query tokens whose top-10 elements contain $d$. $T_2$ includes query tokens whose top-10 elements do not contain $d$. $\\overline{w_{t,d}}$ is the weight in the 10-th element of $t$'s postings list. As a special case, for a document $d$ that doesn't appear in the top-10 elements of any query token $t$, its upper-bound score is thus: \n",
    "\n",
    "$$ \\overline{sim(q,d)} = \\sum_{t\\in q} w_{t,q} \\times \\overline{w_{t,d}}.$$\n",
    "\n",
    "(7.5) If a document's actual score is better than or equal to the actual scores and upper-bound scores of all other documents, it is returned as the query answer. \n",
    "\n",
    "If there isn't such a document, it means we need to go deeper than 10 elements into the postings list of each query token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to Submit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit through Blackboard your source code in a single .py file. You can use any standard Python library. The only non-standard library/package allowed for this assignment is NLTK. You .py file must define at least the following functions:\n",
    "\n",
    "* query(qstring): return a tuple in the form of (filename of the document, score), where the document is the query answer with respect to \"qstring\" according to (7.5). If no document contains any token in the query, return (\"None\",0). If we need more than 10 elements from each posting list, return (\"fetch more\",0).\n",
    "\n",
    "* getidf(token): return the inverse document frequency of a token. If the token doesn't exist in the corpus, return -1. The parameter 'token' is already stemmed. Note the differences between getidf(\"hispan\") and getidf(\"hispanic\") in the examples below. \n",
    "\n",
    "* getweight(filemae,token): return the TF-IDF weight of a token in the document named 'filename'. If the token doesn't exist in the document, return 0. The parameter 'token' is already stemmed. Note that both getweight(\"1960-10-21.txt\",\"reason\") and getweight(\"2012-10-16.txt\",\"hispanic\") return 0, but for different reasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sample results that we should expect from a correct implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print(\"(%s, %.12f)\" % query(\"health insurance wall street\"))\n",
    "\n",
    "(2012-10-03.txt, 0.033877975254)\n",
    "\n",
    "* print(\"(%s, %.12f)\" % query(\"security conference ambassador\"))\n",
    "\n",
    "(1960-10-21.txt, 0.043935804608)\n",
    "\n",
    "* print(\"(%s, %.12f)\" % query(\"particular constitutional amendment\"))\n",
    "\n",
    "(fetch more, 0.000000000000)\n",
    "\n",
    "* print(\"(%s, %.12f)\" % query(\"terror attack\"))\n",
    "\n",
    "(2004-09-30.txt, 0.026893338131)\n",
    "\n",
    "* print(\"(%s, %.12f)\" % query(\"vector entropy\"))\n",
    "\n",
    "(None, 0.000000000000)\n",
    "\n",
    "* print(\"%.12f\" % getweight(\"2012-10-03.txt\",\"health\"))\n",
    "\n",
    "0.008528366190\n",
    "\n",
    "* print(\"%.12f\" % getweight(\"1960-10-21.txt\",\"reason\"))\n",
    "\n",
    "0.000000000000\n",
    "\n",
    "* print(\"%.12f\" % getweight(\"1976-10-22.txt\",\"agenda\"))\n",
    "\n",
    "0.012683891289\n",
    "\n",
    "* print(\"%.12f\" % getweight(\"2012-10-16.txt\",\"hispan\"))\n",
    "\n",
    "0.023489163449\n",
    "\n",
    "* print(\"%.12f\" % getweight(\"2012-10-16.txt\",\"hispanic\"))\n",
    "\n",
    "0.000000000000\n",
    "\n",
    "* print(\"%.12f\" % getidf(\"health\"))\n",
    "\n",
    "0.079181246048\n",
    "\n",
    "* print(\"%.12f\" % getidf(\"agenda\"))\n",
    "\n",
    "0.363177902413\n",
    "\n",
    "* print(\"%.12f\" % getidf(\"vector\"))\n",
    "\n",
    "-1.000000000000\n",
    "\n",
    "* print(\"%.12f\" % getidf(\"reason\"))\n",
    "\n",
    "0.000000000000\n",
    "\n",
    "* print(\"%.12f\" % getidf(\"hispan\"))\n",
    "\n",
    "0.632023214705\n",
    "\n",
    "* print(\"%.12f\" % getidf(\"hispanic\"))\n",
    "\n",
    "-1.000000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your program will be evaluated using the following criteria: \n",
    "\n",
    "* Correctness\n",
    "\n",
    "We will evaluate your code by calling the functions specificed above. So, make sure to use the same function names, parameter names/types/orders as specified above. We will use the above test cases and other queries and tokens to test your program.\n",
    "\n",
    "* Efficiency\n",
    "\n",
    "Don't be satisfied by exhaustive, straightforward implementation. Keep improving its efficiency. An efficient solution should be able to answer a query in a few seconds. \n",
    "\n",
    "* Boundary cases \n",
    "\n",
    "Make sure your program will behave correctly under special cases and even incorrect input. \n",
    "\n",
    "* Clarity, organization, modularity, documentation\n",
    "\n",
    "Follow good coding standards to make your program easy to understand by others and easy to maintain/extend. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
